{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60301/2537656179.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  dataframe = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "dataframe = pd.read_csv(\n",
    "    \"data/metadata.csv\", on_bad_lines=\"warn\", delimiter=\";;\"\n",
    ")  # custom delimiter ';;'\n",
    "# image_file_names = os.listdir(\"data/images\")\n",
    "image_file_names = os.listdir(\"data/retry_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['61.png',\n",
       " '67.png',\n",
       " '70.png',\n",
       " '71.png',\n",
       " '87.png',\n",
       " '88.png',\n",
       " '99.png',\n",
       " '103.png',\n",
       " '129.png',\n",
       " '135.png',\n",
       " '136.png',\n",
       " '192.png',\n",
       " '193.png',\n",
       " '202.png',\n",
       " '203.png',\n",
       " '238.png',\n",
       " '244.png',\n",
       " '250.png',\n",
       " '266.png',\n",
       " '270.png',\n",
       " '272.png',\n",
       " '375.png',\n",
       " '402.png',\n",
       " '406.png',\n",
       " '565.png',\n",
       " '569.png',\n",
       " '593.png',\n",
       " '599.png',\n",
       " '600.png',\n",
       " '604.png',\n",
       " '624.png',\n",
       " '647.png',\n",
       " '652.png',\n",
       " '659.png',\n",
       " '729.png']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_file_names.sort(key=lambda x: int(x.split(\".\")[0]))\n",
    "image_file_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enusring all relvent data is available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>c2t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.png</td>\n",
       "      <td>Start is connected with Check needs for projec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>401.png</td>\n",
       "      <td>Start is connected with Check software. If Che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>402.png</td>\n",
       "      <td>Begin is conected with Check your PC configura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.png</td>\n",
       "      <td>Begin is conected with SUM=0 which is then con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>406.png</td>\n",
       "      <td>Begin is connected with calculate total travel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>818.png</td>\n",
       "      <td>Input is connected with Filtering which is the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>823.png</td>\n",
       "      <td>Application is connected with Login which is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>848.png</td>\n",
       "      <td>Data process is connected with Degree calculat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>888.png</td>\n",
       "      <td>Raw Materials is connected with Melting which ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>891.png</td>\n",
       "      <td>New Budget is connected with Make an edit whic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        file                                                c2t\n",
       "0      0.png  Start is connected with Check needs for projec...\n",
       "1    401.png  Start is connected with Check software. If Che...\n",
       "2    402.png  Begin is conected with Check your PC configura...\n",
       "3      3.png  Begin is conected with SUM=0 which is then con...\n",
       "4    406.png  Begin is connected with calculate total travel...\n",
       "..       ...                                                ...\n",
       "211  818.png  Input is connected with Filtering which is the...\n",
       "212  823.png  Application is connected with Login which is t...\n",
       "213  848.png  Data process is connected with Degree calculat...\n",
       "214  888.png  Raw Materials is connected with Melting which ...\n",
       "215  891.png  New Budget is connected with Make an edit whic...\n",
       "\n",
       "[216 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataframe[~dataframe[\"file\"].isin(image_file_names)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in image_file_names:\n",
    "    if file_name not in dataframe[\"file\"].values:\n",
    "        print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Start is connected with Scan Bar code which is then connected with \"Reader\" decrypts message and sends it to \"3D object management interface\" which is further connected with Check the website. Check the website is connected with The back-end server checks data and compares it with \"3D objects database\" which is then connected with Does data match the detail in \"3D obects database\". If Does data match the detail in \"3D obects database\" is No? then An error message is displayed on the user screen and if Does data match the detail in \"3D obects database\" is Yes? then The 3D object is displayed on the user screen.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe[dataframe[\"file\"] == \"591.png\"][\"c2t\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_1 = image_file_names[:10] # Done\n",
    "batch_2 = image_file_names[10:40] # Done\n",
    "batch_3 = image_file_names[40:70] # Done\n",
    "batch_4 = image_file_names[70:100] # Done\n",
    "batch_5 = image_file_names[100:130] # Done\n",
    "batch_6 = image_file_names[130:160] # Done\n",
    "batch_7 = image_file_names[160:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Literal\n",
    "import dotenv\n",
    "import os\n",
    "import base64\n",
    "from anthropic import Anthropic\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from dataclasses import dataclass\n",
    "from pydantic_ai.models.anthropic import AnthropicModel\n",
    "\n",
    "dotenv.load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDEX = 0\n",
      "fetching output for \"61.png\"\n",
      "ERROR for 61.png : Exceeded maximum retries (8) for result validation =*=*=*=*=*=*=*=*=*=*\n",
      "INDEX = 1\n",
      "fetching output for \"67.png\"\n",
      "got the output from vlm for \"67.png\"\n",
      "writing json for 67.png\n",
      "INDEX = 2\n",
      "fetching output for \"70.png\"\n",
      "ERROR for 70.png : Exceeded maximum retries (8) for result validation =*=*=*=*=*=*=*=*=*=*\n",
      "INDEX = 3\n",
      "fetching output for \"71.png\"\n",
      "ERROR for 71.png : Exceeded maximum retries (8) for result validation =*=*=*=*=*=*=*=*=*=*\n",
      "INDEX = 4\n",
      "fetching output for \"87.png\"\n",
      "ERROR for 87.png : Exceeded maximum retries (8) for result validation =*=*=*=*=*=*=*=*=*=*\n",
      "INDEX = 5\n",
      "fetching output for \"88.png\"\n",
      "ERROR for 88.png : Exceeded maximum retries (8) for result validation =*=*=*=*=*=*=*=*=*=*\n",
      "INDEX = 6\n",
      "fetching output for \"99.png\"\n",
      "ERROR for 99.png : Exceeded maximum retries (8) for result validation =*=*=*=*=*=*=*=*=*=*\n",
      "INDEX = 7\n",
      "fetching output for \"103.png\"\n",
      "ERROR for 103.png : Exceeded maximum retries (8) for result validation =*=*=*=*=*=*=*=*=*=*\n",
      "INDEX = 8\n",
      "fetching output for \"129.png\"\n",
      "ERROR for 129.png : Exceeded maximum retries (8) for result validation =*=*=*=*=*=*=*=*=*=*\n",
      "INDEX = 9\n",
      "fetching output for \"135.png\"\n",
      "ERROR for 135.png : Exceeded maximum retries (8) for result validation =*=*=*=*=*=*=*=*=*=*\n",
      "INDEX = 10\n",
      "fetching output for \"136.png\"\n",
      "ERROR for 136.png : Exceeded maximum retries (8) for result validation =*=*=*=*=*=*=*=*=*=*\n",
      "INDEX = 11\n",
      "fetching output for \"192.png\"\n",
      "got the output from vlm for \"192.png\"\n",
      "writing json for 192.png\n",
      "INDEX = 12\n",
      "fetching output for \"193.png\"\n",
      "ERROR for 193.png : Exceeded maximum retries (8) for result validation =*=*=*=*=*=*=*=*=*=*\n",
      "INDEX = 13\n",
      "fetching output for \"202.png\"\n",
      "ERROR for 202.png : Exceeded maximum retries (8) for result validation =*=*=*=*=*=*=*=*=*=*\n",
      "INDEX = 14\n",
      "fetching output for \"203.png\"\n",
      "ERROR for 203.png : Exceeded maximum retries (8) for result validation =*=*=*=*=*=*=*=*=*=*\n",
      "INDEX = 15\n",
      "fetching output for \"238.png\"\n",
      "ERROR for 238.png : Exceeded maximum retries (8) for result validation =*=*=*=*=*=*=*=*=*=*\n",
      "INDEX = 16\n",
      "fetching output for \"244.png\"\n",
      "ERROR for 244.png : Exceeded maximum retries (8) for result validation =*=*=*=*=*=*=*=*=*=*\n",
      "INDEX = 17\n",
      "fetching output for \"250.png\"\n",
      "ERROR for 250.png : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}} =*=*=*=*=*=*=*=*=*=*\n",
      "INDEX = 18\n",
      "fetching output for \"266.png\"\n",
      "ERROR for 266.png : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}} =*=*=*=*=*=*=*=*=*=*\n",
      "INDEX = 19\n",
      "fetching output for \"270.png\"\n",
      "ERROR for 270.png : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}} =*=*=*=*=*=*=*=*=*=*\n",
      "INDEX = 20\n",
      "fetching output for \"272.png\"\n",
      "ERROR for 272.png : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}} =*=*=*=*=*=*=*=*=*=*\n",
      "INDEX = 21\n",
      "fetching output for \"375.png\"\n",
      "ERROR for 375.png : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}} =*=*=*=*=*=*=*=*=*=*\n",
      "INDEX = 22\n",
      "fetching output for \"402.png\"\n",
      "ERROR for 402.png : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}} =*=*=*=*=*=*=*=*=*=*\n",
      "INDEX = 23\n",
      "fetching output for \"406.png\"\n",
      "ERROR for 406.png : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}} =*=*=*=*=*=*=*=*=*=*\n",
      "INDEX = 24\n",
      "fetching output for \"565.png\"\n",
      "ERROR for 565.png : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}} =*=*=*=*=*=*=*=*=*=*\n",
      "INDEX = 25\n",
      "fetching output for \"569.png\"\n",
      "ERROR for 569.png : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}} =*=*=*=*=*=*=*=*=*=*\n",
      "INDEX = 26\n",
      "fetching output for \"593.png\"\n",
      "ERROR for 593.png : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}} =*=*=*=*=*=*=*=*=*=*\n",
      "INDEX = 27\n",
      "fetching output for \"599.png\"\n",
      "ERROR for 599.png : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}} =*=*=*=*=*=*=*=*=*=*\n",
      "INDEX = 28\n",
      "fetching output for \"600.png\"\n",
      "ERROR for 600.png : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}} =*=*=*=*=*=*=*=*=*=*\n",
      "INDEX = 29\n",
      "fetching output for \"604.png\"\n",
      "ERROR for 604.png : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}} =*=*=*=*=*=*=*=*=*=*\n",
      "INDEX = 30\n",
      "fetching output for \"624.png\"\n",
      "ERROR for 624.png : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}} =*=*=*=*=*=*=*=*=*=*\n",
      "INDEX = 31\n",
      "fetching output for \"647.png\"\n",
      "ERROR for 647.png : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}} =*=*=*=*=*=*=*=*=*=*\n",
      "INDEX = 32\n",
      "fetching output for \"652.png\"\n",
      "ERROR for 652.png : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}} =*=*=*=*=*=*=*=*=*=*\n",
      "INDEX = 33\n",
      "fetching output for \"659.png\"\n",
      "ERROR for 659.png : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}} =*=*=*=*=*=*=*=*=*=*\n",
      "INDEX = 34\n",
      "fetching output for \"729.png\"\n",
      "ERROR for 729.png : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}} =*=*=*=*=*=*=*=*=*=*\n"
     ]
    }
   ],
   "source": [
    "def check_for_env(key: str):\n",
    "    api_key = os.getenv(key)\n",
    "    if api_key is None:\n",
    "        raise Exception(f\"APi key {key} not available\")\n",
    "    return api_key\n",
    "\n",
    "\n",
    "def write_json(data, file_name):\n",
    "    file_name = file_name.split(\".\")[0]\n",
    "    with open(f\"outputs/{file_name}.json\", \"w\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "\n",
    "def get_base64_encoded_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        binary_data = image_file.read()\n",
    "        base_64_encoded_data = base64.b64encode(binary_data)\n",
    "        base64_string = base_64_encoded_data.decode(\"utf-8\")\n",
    "        return base64_string\n",
    "\n",
    "\n",
    "anthropic_api_key = check_for_env(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "\n",
    "class Node(BaseModel):\n",
    "    \"\"\"Structure of a node in the diagram\"\"\"\n",
    "\n",
    "    id: str = Field(description=\"Id of the Node\")\n",
    "    type_of_node: Literal[\"process\", \"decision\", \"delay\", \"terminator\", \"start\"] = (\n",
    "        Field(description=\"The type of node\")\n",
    "    )\n",
    "    shape: Literal[\"task\", \"gateway\", \"start_event\", \"end_event\", \"data_store\"] = Field(\n",
    "        description=\"The shape of the node visulally\"\n",
    "    )\n",
    "    label: str = Field(description=\"Label of the node\")\n",
    "\n",
    "\n",
    "class Edge(BaseModel):\n",
    "    \"\"\"Structure of a edge in the diagram\"\"\"\n",
    "\n",
    "    source_: str = Field(description=\"The ID of the edge's starting node\")\n",
    "    source_type: Literal[\"process\", \"decision\", \"delay\", \"terminator\", \"start\"] = Field(\n",
    "        description=\"The type of the edge's starting node\"\n",
    "    )\n",
    "    source_label: str = Field(description=\"The label of the edge's starting node\")\n",
    "    target: str = Field(description=\"The ID of edge's end node\")\n",
    "    target_type: Literal[\"process\", \"decision\", \"delay\", \"terminator\", \"start\"] = Field(\n",
    "        description=\"The type of the edge's end node\"\n",
    "    )\n",
    "    target_label: str = Field(description=\"The label of the edge's end node\")\n",
    "    type_of_edge: Literal[\"dashed\", \"solid\"] = Field(\n",
    "        default=\"solid\", description=\"The type of edge, visually\"\n",
    "    )\n",
    "    relationship_value: str = Field(\n",
    "        default=\"\",\n",
    "        description=\"The label of the relationship in the image, if present(e.g., 'yes', 'no')\",\n",
    "    )\n",
    "    relationship_type: Literal[\"follows\", \"branches\", \"depends_on\"] = Field(\n",
    "        default=\"follows\",\n",
    "        description=\"Semantic type of the relationship (e.g., 'follows', 'branches', 'depends_on')\",\n",
    "    )\n",
    "\n",
    "\n",
    "class Graph(BaseModel):\n",
    "    \"\"\"Structure of the graph representing the diagram\"\"\"\n",
    "\n",
    "    nodes: List[Node] = Field(description=\"Nodes from the diagram\")\n",
    "    edges: List[Edge] = Field(description=\"Edges from the diagram\")\n",
    "\n",
    "\n",
    "class MultiModalLLMService:\n",
    "    \"\"\"Service to interact with Anthropic multimodal LLMs.\"\"\"\n",
    "\n",
    "    def __init__(self, model: str):\n",
    "        self.client = Anthropic(api_key=anthropic_api_key)\n",
    "        self.model = model\n",
    "\n",
    "    async def perform_task(\n",
    "        self,\n",
    "        diagram_path: str,\n",
    "        max_tokens: int = 2000,\n",
    "    ):\n",
    "        \"\"\"Send an image and prompt to the LLM and return structured output.\"\"\"\n",
    "\n",
    "        message_list = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        \"source\": {\n",
    "                            \"type\": \"base64\",\n",
    "                            \"media_type\": \"image/png\",  # All images are png\n",
    "                            \"data\": get_base64_encoded_image(diagram_path),\n",
    "                        },\n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "        response = self.client.messages.create(\n",
    "            model=self.model,\n",
    "            max_tokens=max_tokens,\n",
    "            messages=message_list,\n",
    "        )\n",
    "        return response.content[0].text\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DiagramDigitizerDependencies:\n",
    "    llm_service: MultiModalLLMService\n",
    "    diagram_path: str\n",
    "\n",
    "\n",
    "diagram_digitizer_agent = Agent(\n",
    "    AnthropicModel(\n",
    "        \"claude-3-5-sonnet-latest\",\n",
    "        api_key=anthropic_api_key,\n",
    "    ),\n",
    "    deps_type=DiagramDigitizerDependencies,\n",
    "    result_type=Graph,\n",
    "    retries=8,\n",
    "    system_prompt=\"\"\"You are an AI model extracting structured information from diagrams.\n",
    "Important Rule: Labels must be strictly preserved without any modification, truncation, rewording, or summarization.\n",
    "\n",
    "    Each label is an identifier and must be extracted exactly as it appears in the diagram.\n",
    "    Do NOT modify punctuation, or word order.\n",
    "    Do NOT attempt to summarize or shorten labels.\n",
    "    The extracted JSON must maintain the full original label text exactly as it appears in the diagram.\n",
    "\n",
    "If you are unsure about a label, extract it as-is without modification rather than trying to \"fix\" it.\n",
    "Consider their shape and translate it's purpose as it is important for the data extraction. only give the json format of the diagram. extract all other information in lowercase and in the same format as the image. But not the labels.\n",
    "\"\"\",\n",
    ")\n",
    "\n",
    "\n",
    "@diagram_digitizer_agent.tool\n",
    "async def extract_diagram_info(ctx: RunContext[DiagramDigitizerDependencies]) -> Graph:\n",
    "    \"\"\"Tool to extract diagram information details from the image\"\"\"\n",
    "    return await ctx.deps.llm_service.perform_task(  # type: ignore\n",
    "        diagram_path=ctx.deps.diagram_path,\n",
    "    )\n",
    "\n",
    "\n",
    "result = None\n",
    "\n",
    "# Doing the for loops in batches\n",
    "async def main():\n",
    "    global result\n",
    "    for index, file_name in enumerate(image_file_names):\n",
    "        try:\n",
    "            image_path = f\"data/retry_error/{file_name}\"\n",
    "            deps = DiagramDigitizerDependencies(\n",
    "                llm_service=MultiModalLLMService(model=\"claude-3-5-sonnet-20241022\"),\n",
    "                diagram_path=image_path,\n",
    "            )\n",
    "            description = dataframe[dataframe[\"file\"] == file_name][\"c2t\"].values[0]\n",
    "            prompt = f\"\"\"Here is the description of the image refer this for correct labels and details \"{description}\" \"\"\"\n",
    "            print(f\"INDEX = {index}\")\n",
    "            print(f'fetching output for \"{file_name}\"')\n",
    "            result = await diagram_digitizer_agent.run(prompt, deps=deps)\n",
    "            print(f'got the output from vlm for \"{file_name}\"')\n",
    "            data = result.data.model_dump()\n",
    "            print(f'writing json for {file_name}')\n",
    "            write_json(data, file_name)\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR for {file_name} : {e} {'='*10}\")\n",
    "            continue\n",
    "    # print(result.usage)\n",
    "\n",
    "await main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
