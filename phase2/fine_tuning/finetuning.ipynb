{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers>=4.49.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (4.49.0)\n",
      "Requirement already satisfied: accelerate in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.33.0)\n",
      "Requirement already satisfied: peft in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.14.0)\n",
      "Requirement already satisfied: bitsandbytes in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.43.3)\n",
      "Requirement already satisfied: datasets in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (3.3.2)\n",
      "Requirement already satisfied: qwen-vl-utils==0.0.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from qwen-vl-utils[decord]==0.0.8) (0.0.8)\n",
      "Requirement already satisfied: comet-ml>=3.31.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (3.49.5)\n",
      "Requirement already satisfied: av in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from qwen-vl-utils==0.0.8->qwen-vl-utils[decord]==0.0.8) (14.2.0)\n",
      "Requirement already satisfied: packaging in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from qwen-vl-utils==0.0.8->qwen-vl-utils[decord]==0.0.8) (23.2)\n",
      "Requirement already satisfied: pillow in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from qwen-vl-utils==0.0.8->qwen-vl-utils[decord]==0.0.8) (10.4.0)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from qwen-vl-utils==0.0.8->qwen-vl-utils[decord]==0.0.8) (2.32.3)\n",
      "Requirement already satisfied: decord in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from qwen-vl-utils[decord]==0.0.8) (0.6.0)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers>=4.49.0) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers>=4.49.0) (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers>=4.49.0) (1.26.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers>=4.49.0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers>=4.49.0) (2024.7.24)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers>=4.49.0) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers>=4.49.0) (0.4.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers>=4.49.0) (4.66.5)\n",
      "Requirement already satisfied: psutil in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate) (6.0.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate) (2.4.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (2.1.4)\n",
      "Requirement already satisfied: xxhash in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: dulwich!=0.20.33,>=0.20.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from comet-ml>=3.31.0) (0.22.8)\n",
      "Requirement already satisfied: everett<3.2.0,>=1.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from everett[ini]<3.2.0,>=1.0.1->comet-ml>=3.31.0) (3.1.0)\n",
      "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from comet-ml>=3.31.0) (4.23.0)\n",
      "Requirement already satisfied: python-box<7.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from comet-ml>=3.31.0) (6.1.0)\n",
      "Requirement already satisfied: requests-toolbelt>=0.8.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from comet-ml>=3.31.0) (1.0.0)\n",
      "Requirement already satisfied: rich>=13.3.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from comet-ml>=3.31.0) (13.8.0)\n",
      "Requirement already satisfied: semantic-version>=2.8.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from comet-ml>=3.31.0) (2.10.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from comet-ml>=3.31.0) (2.22.0)\n",
      "Requirement already satisfied: simplejson in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from comet-ml>=3.31.0) (3.20.1)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from comet-ml>=3.31.0) (2.2.2)\n",
      "Requirement already satisfied: wrapt>=1.11.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from comet-ml>=3.31.0) (1.17.2)\n",
      "Requirement already satisfied: wurlitzer>=1.0.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from comet-ml>=3.31.0) (3.1.1)\n",
      "Requirement already satisfied: configobj in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from everett[ini]<3.2.0,>=1.0.1->comet-ml>=3.31.0) (5.0.9)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers>=4.49.0) (4.12.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml>=3.31.0) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml>=3.31.0) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml>=3.31.0) (0.20.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->qwen-vl-utils==0.0.8->qwen-vl-utils[decord]==0.0.8) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->qwen-vl-utils==0.0.8->qwen-vl-utils[decord]==0.0.8) (3.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->qwen-vl-utils==0.0.8->qwen-vl-utils[decord]==0.0.8) (2024.7.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rich>=13.3.2->comet-ml>=3.31.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rich>=13.3.2->comet-ml>=3.31.0) (2.18.0)\n",
      "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.2)\n",
      "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.6.20)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet-ml>=3.31.0) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"transformers>=4.49.0\" accelerate peft bitsandbytes datasets \"qwen-vl-utils[decord]==0.0.8\" \"comet-ml>=3.31.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import PIL\n",
    "import comet_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 13 18:10:48 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.230.02             Driver Version: 535.230.02   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA L40S                    Off | 00000000:34:00.0 Off |                    0 |\n",
      "| N/A   29C    P0              75W / 350W |    558MiB / 46068MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"zackriya/diagramJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'filename', 'json_string'],\n",
       "        num_rows: 199\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'filename', 'json_string'],\n",
       "        num_rows: 20\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=504x271>,\n",
       " 'filename': '548.png',\n",
       " 'json_string': '{\"nodes\": [{\"id\": \"1\", \"type_of_node\": \"start\", \"shape\": \"start_event\", \"label\": \"Start\"}, {\"id\": \"2\", \"type_of_node\": \"decision\", \"shape\": \"gateway\", \"label\": \"Make decision\"}, {\"id\": \"3\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Do 1\"}, {\"id\": \"4\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Do 2\"}, {\"id\": \"5\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Do 3\"}, {\"id\": \"6\", \"type_of_node\": \"terminator\", \"shape\": \"end_event\", \"label\": \"Stop\"}], \"edges\": [{\"source\": \"1\", \"source_type\": \"start\", \"source_label\": \"Start\", \"target\": \"2\", \"target_type\": \"decision\", \"target_label\": \"Make decision\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"2\", \"source_type\": \"decision\", \"source_label\": \"Make decision\", \"target\": \"3\", \"target_type\": \"process\", \"target_label\": \"Do 1\", \"type_of_edge\": \"solid\", \"relationship_value\": \"outcome 1\", \"relationship_type\": \"branches\"}, {\"source\": \"2\", \"source_type\": \"decision\", \"source_label\": \"Make decision\", \"target\": \"4\", \"target_type\": \"process\", \"target_label\": \"Do 2\", \"type_of_edge\": \"solid\", \"relationship_value\": \"outcome 2\", \"relationship_type\": \"branches\"}, {\"source\": \"3\", \"source_type\": \"process\", \"source_label\": \"Do 1\", \"target\": \"5\", \"target_type\": \"process\", \"target_label\": \"Do 3\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"4\", \"source_type\": \"process\", \"source_label\": \"Do 2\", \"target\": \"5\", \"target_type\": \"process\", \"target_label\": \"Do 3\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"5\", \"source_type\": \"process\", \"source_label\": \"Do 3\", \"target\": \"6\", \"target_type\": \"terminator\", \"target_label\": \"Stop\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}]}'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_MESSAGE = \"\"\"You are a Vision Language Model specialized in extracting structured data from visual representations of process and flow diagrams.\n",
    "Your task is to analyze the provided image of a diagram and extract the relevant information into a well-structured JSON format.\n",
    "The diagram includes details such as nodes and edges. each of them have their own attributes.\n",
    "Focus on identifying key data fields and ensuring the output adheres to the requested JSON structure.\n",
    "Provide only the JSON output based on the extracted information. Avoid additional explanations or comments.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(entry):\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": SYSTEM_MESSAGE}],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    # this image is handled by qwen_vl_utils's process_visio_Info so no need to worry about pil image or path\n",
    "                    \"image\": entry[\"image\"],\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Extract data in JSON format\",\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": entry[\"json_string\"]}],\n",
    "        },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset[\"train\"]\n",
    "eval_dataset = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = [(entry, format_data(entry)) for entry in train_dataset]\n",
    "eval_dataset = [(entry, format_data(entry)) for entry in eval_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=504x271>,\n",
       "  'filename': '548.png',\n",
       "  'json_string': '{\"nodes\": [{\"id\": \"1\", \"type_of_node\": \"start\", \"shape\": \"start_event\", \"label\": \"Start\"}, {\"id\": \"2\", \"type_of_node\": \"decision\", \"shape\": \"gateway\", \"label\": \"Make decision\"}, {\"id\": \"3\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Do 1\"}, {\"id\": \"4\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Do 2\"}, {\"id\": \"5\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Do 3\"}, {\"id\": \"6\", \"type_of_node\": \"terminator\", \"shape\": \"end_event\", \"label\": \"Stop\"}], \"edges\": [{\"source\": \"1\", \"source_type\": \"start\", \"source_label\": \"Start\", \"target\": \"2\", \"target_type\": \"decision\", \"target_label\": \"Make decision\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"2\", \"source_type\": \"decision\", \"source_label\": \"Make decision\", \"target\": \"3\", \"target_type\": \"process\", \"target_label\": \"Do 1\", \"type_of_edge\": \"solid\", \"relationship_value\": \"outcome 1\", \"relationship_type\": \"branches\"}, {\"source\": \"2\", \"source_type\": \"decision\", \"source_label\": \"Make decision\", \"target\": \"4\", \"target_type\": \"process\", \"target_label\": \"Do 2\", \"type_of_edge\": \"solid\", \"relationship_value\": \"outcome 2\", \"relationship_type\": \"branches\"}, {\"source\": \"3\", \"source_type\": \"process\", \"source_label\": \"Do 1\", \"target\": \"5\", \"target_type\": \"process\", \"target_label\": \"Do 3\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"4\", \"source_type\": \"process\", \"source_label\": \"Do 2\", \"target\": \"5\", \"target_type\": \"process\", \"target_label\": \"Do 3\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"5\", \"source_type\": \"process\", \"source_label\": \"Do 3\", \"target\": \"6\", \"target_type\": \"terminator\", \"target_label\": \"Stop\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}]}'},\n",
       " [{'role': 'system',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': 'You are a Vision Language Model specialized in extracting structured data from visual representations of process and flow diagrams.\\nYour task is to analyze the provided image of a diagram and extract the relevant information into a well-structured JSON format.\\nThe diagram includes details such as nodes and edges. each of them have their own attributes.\\nFocus on identifying key data fields and ensuring the output adheres to the requested JSON structure.\\nProvide only the JSON output based on the extracted information. Avoid additional explanations or comments.'}]},\n",
       "  {'role': 'user',\n",
       "   'content': [{'type': 'image',\n",
       "     'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=504x271>},\n",
       "    {'type': 'text', 'text': 'Extract data in JSON format'}]},\n",
       "  {'role': 'assistant',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': '{\"nodes\": [{\"id\": \"1\", \"type_of_node\": \"start\", \"shape\": \"start_event\", \"label\": \"Start\"}, {\"id\": \"2\", \"type_of_node\": \"decision\", \"shape\": \"gateway\", \"label\": \"Make decision\"}, {\"id\": \"3\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Do 1\"}, {\"id\": \"4\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Do 2\"}, {\"id\": \"5\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Do 3\"}, {\"id\": \"6\", \"type_of_node\": \"terminator\", \"shape\": \"end_event\", \"label\": \"Stop\"}], \"edges\": [{\"source\": \"1\", \"source_type\": \"start\", \"source_label\": \"Start\", \"target\": \"2\", \"target_type\": \"decision\", \"target_label\": \"Make decision\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"2\", \"source_type\": \"decision\", \"source_label\": \"Make decision\", \"target\": \"3\", \"target_type\": \"process\", \"target_label\": \"Do 1\", \"type_of_edge\": \"solid\", \"relationship_value\": \"outcome 1\", \"relationship_type\": \"branches\"}, {\"source\": \"2\", \"source_type\": \"decision\", \"source_label\": \"Make decision\", \"target\": \"4\", \"target_type\": \"process\", \"target_label\": \"Do 2\", \"type_of_edge\": \"solid\", \"relationship_value\": \"outcome 2\", \"relationship_type\": \"branches\"}, {\"source\": \"3\", \"source_type\": \"process\", \"source_label\": \"Do 1\", \"target\": \"5\", \"target_type\": \"process\", \"target_label\": \"Do 3\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"4\", \"source_type\": \"process\", \"source_label\": \"Do 2\", \"target\": \"5\", \"target_type\": \"process\", \"target_label\": \"Do 3\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"5\", \"source_type\": \"process\", \"source_label\": \"Do 3\", \"target\": \"6\", \"target_type\": \"terminator\", \"target_label\": \"Stop\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}]}'}]}])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 values, first value is dataset entry, the second one is the chat template with dataset applied\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ec598a8fc7242eebf43302c143d6ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,843,200 || all params: 3,756,466,176 || trainable%: 0.0491\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import get_peft_model, LoraConfig\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, Qwen2_5_VLProcessor\n",
    "\n",
    "\n",
    "MODEL_ID = \"Qwen/Qwen2.5-VL-3B-Instruct\"\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    lora_alpha=16,  # how much the adapted parms contribute\n",
    "    lora_dropout=0.05,  # Dropout for lora layers\n",
    "    r=8,  # lower mean fewer trainable params\n",
    "    bias=\"none\",\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # Query and Value project(common in GPT's)\n",
    "    task_type=\"CAUSAL_LM\",  # For referring predicting next tokens in seq\n",
    ")\n",
    "\n",
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "# Min and Max pixels for balancing memory usage\n",
    "MAX_PIXELS = 1280 * 28 * 28\n",
    "MIN_PIXELS = 256 * 28 * 28\n",
    "\n",
    "processor = Qwen2_5_VLProcessor.from_pretrained(\n",
    "    MODEL_ID, min_pixels=MIN_PIXELS, max_pixels=MAX_PIXELS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "\n",
    "def training_collate_fn(batch):\n",
    "    # Referring to the dataset applied [{'role': 'system....}...]\n",
    "    _, formatted_data = zip(*batch)\n",
    "\n",
    "    texts = [processor.apply_chat_template(entry) for entry in formatted_data]\n",
    "\n",
    "    image_inputs = [\n",
    "        process_vision_info(entry)[0]  # Only takes the PIL image\n",
    "        for entry in formatted_data\n",
    "    ]\n",
    "\n",
    "    model_inputs = processor(\n",
    "        text=texts,\n",
    "        images=image_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    labels = model_inputs[\"input_ids\"].clone()  # Cloning for later masking use\n",
    "\n",
    "    # mask system message and image token IDs in the labels\n",
    "    for i, example in enumerate(formatted_data):\n",
    "        sysuser_conv = example[:-1]\n",
    "        sysuser_text = processor.apply_chat_template(sysuser_conv, tokenize=False)\n",
    "        sysuser_img, _ = process_vision_info(sysuser_conv)\n",
    "\n",
    "        sysuser_inputs = processor(\n",
    "            text=[sysuser_text],\n",
    "            images=[sysuser_img],\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "        )\n",
    "\n",
    "        sysuser_len = sysuser_inputs[\"input_ids\"].shape[1]\n",
    "        labels[i, :sysuser_len] = -100\n",
    "\n",
    "    input_ids = model_inputs[\"input_ids\"]\n",
    "    attention_mask = model_inputs[\"attention_mask\"]\n",
    "    pixel_values = model_inputs[\"pixel_values\"]\n",
    "    image_grid_thw = model_inputs[\"image_grid_thw\"]\n",
    "\n",
    "    return input_ids, attention_mask, pixel_values, image_grid_thw, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluating_collate_fn(batch):\n",
    "    data, formatted_data = zip(*batch)\n",
    "    ground_truth = [entry[\"json_string\"] for entry in data]\n",
    "\n",
    "    # Removing the assistant answer section from the formatted data\n",
    "    formatted_data = [entry[:2] for entry in formatted_data]\n",
    "\n",
    "    texts = [\n",
    "        processor.apply_chat_template(entry, tokenize=False) for entry in formatted_data\n",
    "    ]\n",
    "\n",
    "    image_inputs = [process_vision_info(entry)[0] for entry in formatted_data]\n",
    "\n",
    "    model_inputs = processor(\n",
    "        text=texts,\n",
    "        images=image_inputs,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "    )\n",
    "    input_ids = model_inputs[\"input_ids\"]\n",
    "    attention_mask = model_inputs[\"attention_mask\"]\n",
    "    pixel_values = model_inputs[\"pixel_values\"]\n",
    "    image_grid_thw = model_inputs[\"image_grid_thw\"]\n",
    "\n",
    "    return input_ids, attention_mask, pixel_values, image_grid_thw, ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=training_collate_fn,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")\n",
    "eval_loader = DataLoader(\n",
    "    eval_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=evaluating_collate_fn,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q lightning nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CometLogger will be initialized in online mode\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.loggers import CometLogger\n",
    "\n",
    "comet_logger = CometLogger(\n",
    "    api_key=os.environ.get(\"COMET_API_KEY\"),\n",
    "    project_name=\"qwen2-5-vl-finetune\",\n",
    "    workspace=\"mohammedsafvan\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from nltk import edit_distance\n",
    "from torch.optim import AdamW\n",
    "\n",
    "\n",
    "class Qwen2_5_Trainer(L.LightningModule):\n",
    "    def __init__(self, model, processor, config):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.processor = processor\n",
    "        self.config = config\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        input_ids, attention_mask, pixel_values, image_grid_thw, labels = batch\n",
    "        outputs = self.model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            pixel_values=pixel_values,\n",
    "            image_grid_thw=image_grid_thw,\n",
    "            labels=labels,  # Masked labels\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        self.log(\"train_loss\", loss, logger=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        input_ids, attention_mask, pixel_values, image_grid_thw, ground_truths = batch\n",
    "        generated_ids = self.model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            pixel_values=pixel_values,\n",
    "            image_grid_thw=image_grid_thw,\n",
    "            max_new_tokens=1024,\n",
    "        )\n",
    "\n",
    "        # The output(generated) tokens includes the input tokens. So trimming out the input_ids from the output_ids\n",
    "        trimmed_generated_ids = [\n",
    "            out_ids[len(in_ids) :] for in_ids, out_ids in zip(input_ids, generated_ids)\n",
    "        ]\n",
    "\n",
    "        generated_json = self.processor.batch_decode(\n",
    "            trimmed_generated_ids,\n",
    "            skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=False,\n",
    "        )\n",
    "        scores = []\n",
    "        for generated, ground_truth in zip(generated_json, ground_truths):\n",
    "            score = edit_distance(generated, ground_truth)\n",
    "            score = score / max(len(generated), len(ground_truth))\n",
    "            scores.append(score)\n",
    "\n",
    "            print(f\"Generated JSON : {generated}\")\n",
    "            print(f\"Ground Truth(JSON): {ground_truth}\")\n",
    "            print(f\"Score: {score}\")\n",
    "\n",
    "        score = sum(scores) / len(scores)\n",
    "        self.log(\n",
    "            \"val_edit_distance\",\n",
    "            score,\n",
    "            logger=True,\n",
    "            prog_bar=True,\n",
    "            batch_size=self.config.get(\"batch_size\"),\n",
    "        )\n",
    "        return scores\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.model.parameters(), lr=self.config.get(\"lr\"))\n",
    "        return optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self.config.get(\"batch_size\"),\n",
    "            collate_fn=training_collate_fn,\n",
    "            shuffle=True,\n",
    "            num_workers=10,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            eval_dataset,\n",
    "            batch_size=self.config.get(\"batch_size\"),\n",
    "            collate_fn=evaluating_collate_fn,\n",
    "            num_workers=10,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"max_epochs\": 10,\n",
    "    \"batch_size\": 2,\n",
    "    \"lr\": 2e-4,  # 5\n",
    "    \"check_val_every_n_epoch\": 2,\n",
    "    \"gradient_clip_val\": 1.0,\n",
    "    \"accumulate_grad_batches\": 8,\n",
    "    # \"accumulate_grad_batches\":2,\n",
    "    \"num_nodes\": 1,\n",
    "    \"warmup_steps\": 50,\n",
    "    \"result_path\": \"qwen2.5-3b-instruct-diagram-json(second)\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_module = Qwen2_5_Trainer(model, processor, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import Callback\n",
    "\n",
    "# minimum val_edit_distance is good\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor=\"val_edit_distance\", patience=3, verbose=False, mode=\"min\"\n",
    ")\n",
    "\n",
    "\n",
    "class SaveCheckpoint(Callback):\n",
    "    def __init__(self, result_path):\n",
    "        self.result_path = result_path\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        checkpoint_path = f\"{self.result_path}/{self.epoch}\"\n",
    "        os.makedirs(checkpoint_path, exist_ok=True)\n",
    "\n",
    "        pl_module.processor.save_pretrained(checkpoint_path)\n",
    "        pl_module.model.save_pretrained(checkpoint_path)\n",
    "        print(f\"Checkpoint saved at {checkpoint_path}\")\n",
    "\n",
    "        self.epoch += 1\n",
    "\n",
    "    def on_train_end(self, trainer, pl_module):\n",
    "        checkpoint_path = f\"{self.result_path}/latest\"\n",
    "        os.makedirs(checkpoint_path, exist_ok=True)\n",
    "\n",
    "        pl_module.processor.save_pretrained(checkpoint_path)\n",
    "        pl_module.model.save_pretrained(checkpoint_path)\n",
    "        print(f\"(Train Ended) -- Checkpoint saved at {checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    devices=[0],  # -1 refers to use all available gpu's\n",
    "    max_epochs=config.get(\"max_epochs\"),\n",
    "    check_val_every_n_epoch=config.get(\"check_val_every_n_epoch\"),\n",
    "    gradient_clip_val=config.get(\"gradient_clip_val\"),\n",
    "    accumulate_grad_batches=config.get(\"accumulate_grad_batches\"),\n",
    "    limit_val_batches=1,\n",
    "    num_sanity_val_steps=0,\n",
    "    log_every_n_steps=1,\n",
    "    callbacks=[early_stopping_callback, SaveCheckpoint(config.get(\"result_path\"))],\n",
    "    logger=comet_logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA L40S') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/mohammedsafvan/qwen2-5-vl-finetune/1bf2a0473f5c4c4cb18e2a22a4eda764\n",
      "\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                 | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | model | PeftModelForCausalLM | 3.8 B  | train\n",
      "-------------------------------------------------------\n",
      "1.8 M     Trainable params\n",
      "3.8 B     Non-trainable params\n",
      "3.8 B     Total params\n",
      "15,025.865Total estimated model params size (MB)\n",
      "722       Modules in train mode\n",
      "874       Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e54acd7e05a43fdb2d9ae755f938917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at qwen2.5-3b-instruct-diagram-json/0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc70e26d4eb4db1b3159533383e6e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON : nodes [\n",
      "    {\n",
      "        \"name\": \"Start\",\n",
      "        \"type\": \"start\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"Order 1\",\n",
      "        \"type\": \"process\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"Create\",\n",
      "        \"type\": \"process\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"Flowchart\",\n",
      "        \"type\": \"process\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"Document\",\n",
      "        \"type\": \"process\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"Code\",\n",
      "        \"type\": \"process\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"End\",\n",
      "        \"type\": \"end\"\n",
      "    }\n",
      "]\n",
      "Ground Truth(JSON): {\"nodes\": [{\"id\": \"1\", \"type_of_node\": \"start\", \"shape\": \"start_event\", \"label\": \"Start\"}, {\"id\": \"2\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Order 1\"}, {\"id\": \"3\", \"type_of_node\": \"decision\", \"shape\": \"gateway\", \"label\": \"Accept?\"}, {\"id\": \"4\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Create\"}, {\"id\": \"5\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Flowchart\"}, {\"id\": \"6\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Document\"}, {\"id\": \"7\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Code\"}, {\"id\": \"8\", \"type_of_node\": \"terminator\", \"shape\": \"end_event\", \"label\": \"End\"}], \"edges\": [{\"source\": \"1\", \"source_type\": \"start\", \"source_label\": \"Start\", \"target\": \"2\", \"target_type\": \"process\", \"target_label\": \"Order 1\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"2\", \"source_type\": \"process\", \"source_label\": \"Order 1\", \"target\": \"3\", \"target_type\": \"decision\", \"target_label\": \"Accept?\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"3\", \"source_type\": \"decision\", \"source_label\": \"Accept?\", \"target\": \"4\", \"target_type\": \"process\", \"target_label\": \"Create\", \"type_of_edge\": \"solid\", \"relationship_value\": \"Yes\", \"relationship_type\": \"branches\"}, {\"source\": \"4\", \"source_type\": \"process\", \"source_label\": \"Create\", \"target\": \"5\", \"target_type\": \"process\", \"target_label\": \"Flowchart\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"3\", \"source_type\": \"decision\", \"source_label\": \"Accept?\", \"target\": \"6\", \"target_type\": \"process\", \"target_label\": \"Document\", \"type_of_edge\": \"solid\", \"relationship_value\": \"No\", \"relationship_type\": \"branches\"}, {\"source\": \"5\", \"source_type\": \"process\", \"source_label\": \"Flowchart\", \"target\": \"6\", \"target_type\": \"process\", \"target_label\": \"Document\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"6\", \"source_type\": \"process\", \"source_label\": \"Document\", \"target\": \"7\", \"target_type\": \"process\", \"target_label\": \"Code\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"7\", \"source_type\": \"process\", \"source_label\": \"Code\", \"target\": \"8\", \"target_type\": \"terminator\", \"target_label\": \"End\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}]}\n",
      "Score: 0.8462809917355372\n",
      "Generated JSON : \n",
      "Ground Truth(JSON): {\"nodes\": [{\"id\": \"1\", \"type_of_node\": \"start\", \"shape\": \"start_event\", \"label\": \"Start\"}, {\"id\": \"2\", \"type_of_node\": \"decision\", \"shape\": \"gateway\", \"label\": \"If condition\"}, {\"id\": \"3\", \"type_of_node\": \"decision\", \"shape\": \"gateway\", \"label\": \"Nested if condition\"}, {\"id\": \"4\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"If Body\"}, {\"id\": \"5\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Nested if Body\"}, {\"id\": \"6\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Pass\"}, {\"id\": \"7\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Statement just below if\"}, {\"id\": \"8\", \"type_of_node\": \"terminator\", \"shape\": \"end_event\", \"label\": \"Exit\"}], \"edges\": [{\"source\": \"1\", \"source_type\": \"start\", \"source_label\": \"Start\", \"target\": \"2\", \"target_type\": \"decision\", \"target_label\": \"If condition\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"2\", \"source_type\": \"decision\", \"source_label\": \"If condition\", \"target\": \"3\", \"target_type\": \"decision\", \"target_label\": \"Nested if condition\", \"type_of_edge\": \"solid\", \"relationship_value\": \"False\", \"relationship_type\": \"branches\"}, {\"source\": \"2\", \"source_type\": \"decision\", \"source_label\": \"If condition\", \"target\": \"4\", \"target_type\": \"process\", \"target_label\": \"If Body\", \"type_of_edge\": \"solid\", \"relationship_value\": \"True\", \"relationship_type\": \"branches\"}, {\"source\": \"3\", \"source_type\": \"decision\", \"source_label\": \"Nested if condition\", \"target\": \"6\", \"target_type\": \"process\", \"target_label\": \"Pass\", \"type_of_edge\": \"solid\", \"relationship_value\": \"False\", \"relationship_type\": \"branches\"}, {\"source\": \"3\", \"source_type\": \"decision\", \"source_label\": \"Nested if condition\", \"target\": \"5\", \"target_type\": \"process\", \"target_label\": \"Nested if Body\", \"type_of_edge\": \"solid\", \"relationship_value\": \"True\", \"relationship_type\": \"branches\"}, {\"source\": \"4\", \"source_type\": \"process\", \"source_label\": \"If Body\", \"target\": \"7\", \"target_type\": \"process\", \"target_label\": \"Statement just below if\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"5\", \"source_type\": \"process\", \"source_label\": \"Nested if Body\", \"target\": \"7\", \"target_type\": \"process\", \"target_label\": \"Statement just below if\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"6\", \"source_type\": \"process\", \"source_label\": \"Pass\", \"target\": \"7\", \"target_type\": \"process\", \"target_label\": \"Statement just below if\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"7\", \"source_type\": \"process\", \"source_label\": \"Statement just below if\", \"target\": \"8\", \"target_type\": \"terminator\", \"target_label\": \"Exit\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}]}\n",
      "Score: 1.0\n",
      "Checkpoint saved at qwen2.5-3b-instruct-diagram-json/1\n",
      "Checkpoint saved at qwen2.5-3b-instruct-diagram-json/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "236ba0438a3f4e428b9c40186fc6749f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON : assistant\n",
      "{\"nodes\": [{\"id\": \"1\", \"type\": \"start\", \"label\": \"Start\"}, {\"id\": \"2\", \"type\": \"process\", \"label\": \"Order 1\"}, {\"id\": \"3\", \"type\": \"decision\", \"label\": \"Accept?\"}, {\"id\": \"4\", \"type\": \"process\", \"label\": \"Create\"}, {\"id\": \"5\", \"type\": \"process\", \"label\": \"Flowchart\"}, {\"id\": \"6\", \"type\": \"process\", \"label\": \"Document\"}, {\"id\": \"7\", \"type\": \"process\", \"label\": \"Code\"}, {\"id\": \"8\", \"type\": \"end\", \"label\": \"End\"}], \"edges\": [{\"source\": \"1\", \"target\": \"2\", \"type\": \"flow\", \"label\": \"\"}, {\"source\": \"2\", \"target\": \"3\", \"type\": \"flow\", \"label\": \"\"}, {\"source\": \"3\", \"target\": \"4\", \"type\": \"flow\", \"label\": \"Yes\"}, {\"source\": \"3\", \"target\": \"6\", \"type\": \"flow\", \"label\": \"No\"}, {\"source\": \"4\", \"target\": \"5\", \"type\": \"flow\", \"label\": \"\"}, {\"source\": \"5\", \"target\": \"6\", \"type\": \"flow\", \"label\": \"\"}, {\"source\": \"6\", \"target\": \"7\", \"type\": \"flow\", \"label\": \"\"}, {\"source\": \"7\", \"target\": \"8\", \"type\": \"flow\", \"label\": \"\"}]}\n",
      "Ground Truth(JSON): {\"nodes\": [{\"id\": \"1\", \"type_of_node\": \"start\", \"shape\": \"start_event\", \"label\": \"Start\"}, {\"id\": \"2\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Order 1\"}, {\"id\": \"3\", \"type_of_node\": \"decision\", \"shape\": \"gateway\", \"label\": \"Accept?\"}, {\"id\": \"4\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Create\"}, {\"id\": \"5\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Flowchart\"}, {\"id\": \"6\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Document\"}, {\"id\": \"7\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Code\"}, {\"id\": \"8\", \"type_of_node\": \"terminator\", \"shape\": \"end_event\", \"label\": \"End\"}], \"edges\": [{\"source\": \"1\", \"source_type\": \"start\", \"source_label\": \"Start\", \"target\": \"2\", \"target_type\": \"process\", \"target_label\": \"Order 1\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"2\", \"source_type\": \"process\", \"source_label\": \"Order 1\", \"target\": \"3\", \"target_type\": \"decision\", \"target_label\": \"Accept?\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"3\", \"source_type\": \"decision\", \"source_label\": \"Accept?\", \"target\": \"4\", \"target_type\": \"process\", \"target_label\": \"Create\", \"type_of_edge\": \"solid\", \"relationship_value\": \"Yes\", \"relationship_type\": \"branches\"}, {\"source\": \"4\", \"source_type\": \"process\", \"source_label\": \"Create\", \"target\": \"5\", \"target_type\": \"process\", \"target_label\": \"Flowchart\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"3\", \"source_type\": \"decision\", \"source_label\": \"Accept?\", \"target\": \"6\", \"target_type\": \"process\", \"target_label\": \"Document\", \"type_of_edge\": \"solid\", \"relationship_value\": \"No\", \"relationship_type\": \"branches\"}, {\"source\": \"5\", \"source_type\": \"process\", \"source_label\": \"Flowchart\", \"target\": \"6\", \"target_type\": \"process\", \"target_label\": \"Document\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"6\", \"source_type\": \"process\", \"source_label\": \"Document\", \"target\": \"7\", \"target_type\": \"process\", \"target_label\": \"Code\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"7\", \"source_type\": \"process\", \"source_label\": \"Code\", \"target\": \"8\", \"target_type\": \"terminator\", \"target_label\": \"End\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}]}\n",
      "Score: 0.6359504132231405\n",
      "Generated JSON : \n",
      "Ground Truth(JSON): {\"nodes\": [{\"id\": \"1\", \"type_of_node\": \"start\", \"shape\": \"start_event\", \"label\": \"Start\"}, {\"id\": \"2\", \"type_of_node\": \"decision\", \"shape\": \"gateway\", \"label\": \"If condition\"}, {\"id\": \"3\", \"type_of_node\": \"decision\", \"shape\": \"gateway\", \"label\": \"Nested if condition\"}, {\"id\": \"4\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"If Body\"}, {\"id\": \"5\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Nested if Body\"}, {\"id\": \"6\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Pass\"}, {\"id\": \"7\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Statement just below if\"}, {\"id\": \"8\", \"type_of_node\": \"terminator\", \"shape\": \"end_event\", \"label\": \"Exit\"}], \"edges\": [{\"source\": \"1\", \"source_type\": \"start\", \"source_label\": \"Start\", \"target\": \"2\", \"target_type\": \"decision\", \"target_label\": \"If condition\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"2\", \"source_type\": \"decision\", \"source_label\": \"If condition\", \"target\": \"3\", \"target_type\": \"decision\", \"target_label\": \"Nested if condition\", \"type_of_edge\": \"solid\", \"relationship_value\": \"False\", \"relationship_type\": \"branches\"}, {\"source\": \"2\", \"source_type\": \"decision\", \"source_label\": \"If condition\", \"target\": \"4\", \"target_type\": \"process\", \"target_label\": \"If Body\", \"type_of_edge\": \"solid\", \"relationship_value\": \"True\", \"relationship_type\": \"branches\"}, {\"source\": \"3\", \"source_type\": \"decision\", \"source_label\": \"Nested if condition\", \"target\": \"6\", \"target_type\": \"process\", \"target_label\": \"Pass\", \"type_of_edge\": \"solid\", \"relationship_value\": \"False\", \"relationship_type\": \"branches\"}, {\"source\": \"3\", \"source_type\": \"decision\", \"source_label\": \"Nested if condition\", \"target\": \"5\", \"target_type\": \"process\", \"target_label\": \"Nested if Body\", \"type_of_edge\": \"solid\", \"relationship_value\": \"True\", \"relationship_type\": \"branches\"}, {\"source\": \"4\", \"source_type\": \"process\", \"source_label\": \"If Body\", \"target\": \"7\", \"target_type\": \"process\", \"target_label\": \"Statement just below if\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"5\", \"source_type\": \"process\", \"source_label\": \"Nested if Body\", \"target\": \"7\", \"target_type\": \"process\", \"target_label\": \"Statement just below if\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"6\", \"source_type\": \"process\", \"source_label\": \"Pass\", \"target\": \"7\", \"target_type\": \"process\", \"target_label\": \"Statement just below if\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"7\", \"source_type\": \"process\", \"source_label\": \"Statement just below if\", \"target\": \"8\", \"target_type\": \"terminator\", \"target_label\": \"Exit\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}]}\n",
      "Score: 1.0\n",
      "Checkpoint saved at qwen2.5-3b-instruct-diagram-json/3\n",
      "Checkpoint saved at qwen2.5-3b-instruct-diagram-json/4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57b539e2f21146eebac488cb964ece35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON : assistant\n",
      "{\"nodes\": [{\"id\": \"1\", \"type_of_node\": \"start\", \"shape\": \"start_event\", \"label\": \"Start\"}, {\"id\": \"2\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Order 1\"}, {\"id\": \"3\", \"type_of_node\": \"decision\", \"shape\": \"gateway\", \"label\": \"Accept?\"}, {\"id\": \"4\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Create\"}, {\"id\": \"5\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Flowchart\"}, {\"id\": \"6\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Document\"}, {\"id\": \"7\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Code\"}, {\"id\": \"8\", \"type_of_node\": \"terminator\", \"shape\": \"end_event\", \"label\": \"End\"}], \"edges\": [{\"source\": \"1\", \"source_type\": \"start\", \"source_label\": \"Start\", \"target\": \"2\", \"target_type\": \"process\", \"target_label\": \"Order 1\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"2\", \"source_type\": \"process\", \"source_label\": \"Order 1\", \"target\": \"3\", \"target_type\": \"decision\", \"target_label\": \"Accept?\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"3\", \"source_type\": \"decision\", \"source_label\": \"Accept?\", \"target\": \"4\", \"target_type\": \"process\", \"target_label\": \"Create\", \"type_of_edge\": \"solid\", \"relationship_value\": \"Yes\", \"relationship_type\": \"branches\"}, {\"source\": \"3\", \"source_type\": \"decision\", \"source_label\": \"Accept?\", \"target\": \"6\", \"target_type\": \"process\", \"target_label\": \"Document\", \"type_of_edge\": \"solid\", \"relationship_value\": \"No\", \"relationship_type\": \"branches\"}, {\"source\": \"4\", \"source_type\": \"process\", \"source_label\": \"Create\", \"target\": \"5\", \"target_type\": \"process\", \"target_label\": \"Flowchart\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"6\", \"source_type\": \"process\", \"source_label\": \"Document\", \"target\": \"7\", \"target_type\": \"process\", \"target_label\": \"Code\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"7\", \"source_type\": \"process\", \"source_label\": \"Code\", \"target\": \"8\", \"target_type\": \"terminator\", \"target_label\": \"End\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}]}\n",
      "Ground Truth(JSON): {\"nodes\": [{\"id\": \"1\", \"type_of_node\": \"start\", \"shape\": \"start_event\", \"label\": \"Start\"}, {\"id\": \"2\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Order 1\"}, {\"id\": \"3\", \"type_of_node\": \"decision\", \"shape\": \"gateway\", \"label\": \"Accept?\"}, {\"id\": \"4\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Create\"}, {\"id\": \"5\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Flowchart\"}, {\"id\": \"6\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Document\"}, {\"id\": \"7\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Code\"}, {\"id\": \"8\", \"type_of_node\": \"terminator\", \"shape\": \"end_event\", \"label\": \"End\"}], \"edges\": [{\"source\": \"1\", \"source_type\": \"start\", \"source_label\": \"Start\", \"target\": \"2\", \"target_type\": \"process\", \"target_label\": \"Order 1\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"2\", \"source_type\": \"process\", \"source_label\": \"Order 1\", \"target\": \"3\", \"target_type\": \"decision\", \"target_label\": \"Accept?\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"3\", \"source_type\": \"decision\", \"source_label\": \"Accept?\", \"target\": \"4\", \"target_type\": \"process\", \"target_label\": \"Create\", \"type_of_edge\": \"solid\", \"relationship_value\": \"Yes\", \"relationship_type\": \"branches\"}, {\"source\": \"4\", \"source_type\": \"process\", \"source_label\": \"Create\", \"target\": \"5\", \"target_type\": \"process\", \"target_label\": \"Flowchart\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"3\", \"source_type\": \"decision\", \"source_label\": \"Accept?\", \"target\": \"6\", \"target_type\": \"process\", \"target_label\": \"Document\", \"type_of_edge\": \"solid\", \"relationship_value\": \"No\", \"relationship_type\": \"branches\"}, {\"source\": \"5\", \"source_type\": \"process\", \"source_label\": \"Flowchart\", \"target\": \"6\", \"target_type\": \"process\", \"target_label\": \"Document\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"6\", \"source_type\": \"process\", \"source_label\": \"Document\", \"target\": \"7\", \"target_type\": \"process\", \"target_label\": \"Code\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"7\", \"source_type\": \"process\", \"source_label\": \"Code\", \"target\": \"8\", \"target_type\": \"terminator\", \"target_label\": \"End\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}]}\n",
      "Score: 0.10289256198347108\n",
      "Generated JSON : \n",
      "Ground Truth(JSON): {\"nodes\": [{\"id\": \"1\", \"type_of_node\": \"start\", \"shape\": \"start_event\", \"label\": \"Start\"}, {\"id\": \"2\", \"type_of_node\": \"decision\", \"shape\": \"gateway\", \"label\": \"If condition\"}, {\"id\": \"3\", \"type_of_node\": \"decision\", \"shape\": \"gateway\", \"label\": \"Nested if condition\"}, {\"id\": \"4\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"If Body\"}, {\"id\": \"5\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Nested if Body\"}, {\"id\": \"6\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Pass\"}, {\"id\": \"7\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Statement just below if\"}, {\"id\": \"8\", \"type_of_node\": \"terminator\", \"shape\": \"end_event\", \"label\": \"Exit\"}], \"edges\": [{\"source\": \"1\", \"source_type\": \"start\", \"source_label\": \"Start\", \"target\": \"2\", \"target_type\": \"decision\", \"target_label\": \"If condition\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"2\", \"source_type\": \"decision\", \"source_label\": \"If condition\", \"target\": \"3\", \"target_type\": \"decision\", \"target_label\": \"Nested if condition\", \"type_of_edge\": \"solid\", \"relationship_value\": \"False\", \"relationship_type\": \"branches\"}, {\"source\": \"2\", \"source_type\": \"decision\", \"source_label\": \"If condition\", \"target\": \"4\", \"target_type\": \"process\", \"target_label\": \"If Body\", \"type_of_edge\": \"solid\", \"relationship_value\": \"True\", \"relationship_type\": \"branches\"}, {\"source\": \"3\", \"source_type\": \"decision\", \"source_label\": \"Nested if condition\", \"target\": \"6\", \"target_type\": \"process\", \"target_label\": \"Pass\", \"type_of_edge\": \"solid\", \"relationship_value\": \"False\", \"relationship_type\": \"branches\"}, {\"source\": \"3\", \"source_type\": \"decision\", \"source_label\": \"Nested if condition\", \"target\": \"5\", \"target_type\": \"process\", \"target_label\": \"Nested if Body\", \"type_of_edge\": \"solid\", \"relationship_value\": \"True\", \"relationship_type\": \"branches\"}, {\"source\": \"4\", \"source_type\": \"process\", \"source_label\": \"If Body\", \"target\": \"7\", \"target_type\": \"process\", \"target_label\": \"Statement just below if\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"5\", \"source_type\": \"process\", \"source_label\": \"Nested if Body\", \"target\": \"7\", \"target_type\": \"process\", \"target_label\": \"Statement just below if\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"6\", \"source_type\": \"process\", \"source_label\": \"Pass\", \"target\": \"7\", \"target_type\": \"process\", \"target_label\": \"Statement just below if\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"7\", \"source_type\": \"process\", \"source_label\": \"Statement just below if\", \"target\": \"8\", \"target_type\": \"terminator\", \"target_label\": \"Exit\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}]}\n",
      "Score: 1.0\n",
      "Checkpoint saved at qwen2.5-3b-instruct-diagram-json/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/utils/other.py:716: UserWarning: Unable to fetch remote file due to the following error (ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 12e2fbaf-ebb5-4369-9c34-c06cb5d88ef0)') - silently ignoring the lookup for the file config.json in Qwen/Qwen2.5-VL-3B-Instruct.\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in Qwen/Qwen2.5-VL-3B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at qwen2.5-3b-instruct-diagram-json/6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a9f8f4ab3a74b29ada4883830c3cd61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON : assistant\n",
      "{\"nodes\": [{\"id\": \"1\", \"type_of_node\": \"start\", \"shape\": \"start_event\", \"label\": \"Start\"}, {\"id\": \"2\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Order 1\"}, {\"id\": \"3\", \"type_of_node\": \"decision\", \"shape\": \"gateway\", \"label\": \"Accept?\"}, {\"id\": \"4\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Create\"}, {\"id\": \"5\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Flowchart\"}, {\"id\": \"6\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Document\"}, {\"id\": \"7\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Code\"}, {\"id\": \"8\", \"type_of_node\": \"terminator\", \"shape\": \"end_event\", \"label\": \"End\"}], \"edges\": [{\"source\": \"1\", \"source_type\": \"start\", \"source_label\": \"Start\", \"target\": \"2\", \"target_type\": \"process\", \"target_label\": \"Order 1\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"2\", \"source_type\": \"process\", \"source_label\": \"Order 1\", \"target\": \"3\", \"target_type\": \"decision\", \"target_label\": \"Accept?\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"3\", \"source_type\": \"decision\", \"source_label\": \"Accept?\", \"target\": \"4\", \"target_type\": \"process\", \"target_label\": \"Create\", \"type_of_edge\": \"solid\", \"relationship_value\": \"Yes\", \"relationship_type\": \"branches\"}, {\"source\": \"3\", \"source_type\": \"decision\", \"source_label\": \"Accept?\", \"target\": \"6\", \"target_type\": \"process\", \"target_label\": \"Document\", \"type_of_edge\": \"solid\", \"relationship_value\": \"No\", \"relationship_type\": \"branches\"}, {\"source\": \"4\", \"source_type\": \"process\", \"source_label\": \"Create\", \"target\": \"5\", \"target_type\": \"process\", \"target_label\": \"Flowchart\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"5\", \"source_type\": \"process\", \"source_label\": \"Flowchart\", \"target\": \"6\", \"target_type\": \"process\", \"target_label\": \"Document\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"6\", \"source_type\": \"process\", \"source_label\": \"Document\", \"target\": \"7\", \"target_type\": \"process\", \"target_label\": \"Code\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"7\", \"source_type\": \"process\", \"source_label\": \"Code\", \"target\": \"8\", \"target_type\": \"terminator\", \"target_label\": \"End\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}]}\n",
      "Ground Truth(JSON): {\"nodes\": [{\"id\": \"1\", \"type_of_node\": \"start\", \"shape\": \"start_event\", \"label\": \"Start\"}, {\"id\": \"2\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Order 1\"}, {\"id\": \"3\", \"type_of_node\": \"decision\", \"shape\": \"gateway\", \"label\": \"Accept?\"}, {\"id\": \"4\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Create\"}, {\"id\": \"5\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Flowchart\"}, {\"id\": \"6\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Document\"}, {\"id\": \"7\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Code\"}, {\"id\": \"8\", \"type_of_node\": \"terminator\", \"shape\": \"end_event\", \"label\": \"End\"}], \"edges\": [{\"source\": \"1\", \"source_type\": \"start\", \"source_label\": \"Start\", \"target\": \"2\", \"target_type\": \"process\", \"target_label\": \"Order 1\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"2\", \"source_type\": \"process\", \"source_label\": \"Order 1\", \"target\": \"3\", \"target_type\": \"decision\", \"target_label\": \"Accept?\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"3\", \"source_type\": \"decision\", \"source_label\": \"Accept?\", \"target\": \"4\", \"target_type\": \"process\", \"target_label\": \"Create\", \"type_of_edge\": \"solid\", \"relationship_value\": \"Yes\", \"relationship_type\": \"branches\"}, {\"source\": \"4\", \"source_type\": \"process\", \"source_label\": \"Create\", \"target\": \"5\", \"target_type\": \"process\", \"target_label\": \"Flowchart\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"3\", \"source_type\": \"decision\", \"source_label\": \"Accept?\", \"target\": \"6\", \"target_type\": \"process\", \"target_label\": \"Document\", \"type_of_edge\": \"solid\", \"relationship_value\": \"No\", \"relationship_type\": \"branches\"}, {\"source\": \"5\", \"source_type\": \"process\", \"source_label\": \"Flowchart\", \"target\": \"6\", \"target_type\": \"process\", \"target_label\": \"Document\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"6\", \"source_type\": \"process\", \"source_label\": \"Document\", \"target\": \"7\", \"target_type\": \"process\", \"target_label\": \"Code\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"7\", \"source_type\": \"process\", \"source_label\": \"Code\", \"target\": \"8\", \"target_type\": \"terminator\", \"target_label\": \"End\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}]}\n",
      "Score: 0.02880658436213992\n",
      "Generated JSON : \n",
      "Ground Truth(JSON): {\"nodes\": [{\"id\": \"1\", \"type_of_node\": \"start\", \"shape\": \"start_event\", \"label\": \"Start\"}, {\"id\": \"2\", \"type_of_node\": \"decision\", \"shape\": \"gateway\", \"label\": \"If condition\"}, {\"id\": \"3\", \"type_of_node\": \"decision\", \"shape\": \"gateway\", \"label\": \"Nested if condition\"}, {\"id\": \"4\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"If Body\"}, {\"id\": \"5\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Nested if Body\"}, {\"id\": \"6\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Pass\"}, {\"id\": \"7\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Statement just below if\"}, {\"id\": \"8\", \"type_of_node\": \"terminator\", \"shape\": \"end_event\", \"label\": \"Exit\"}], \"edges\": [{\"source\": \"1\", \"source_type\": \"start\", \"source_label\": \"Start\", \"target\": \"2\", \"target_type\": \"decision\", \"target_label\": \"If condition\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"2\", \"source_type\": \"decision\", \"source_label\": \"If condition\", \"target\": \"3\", \"target_type\": \"decision\", \"target_label\": \"Nested if condition\", \"type_of_edge\": \"solid\", \"relationship_value\": \"False\", \"relationship_type\": \"branches\"}, {\"source\": \"2\", \"source_type\": \"decision\", \"source_label\": \"If condition\", \"target\": \"4\", \"target_type\": \"process\", \"target_label\": \"If Body\", \"type_of_edge\": \"solid\", \"relationship_value\": \"True\", \"relationship_type\": \"branches\"}, {\"source\": \"3\", \"source_type\": \"decision\", \"source_label\": \"Nested if condition\", \"target\": \"6\", \"target_type\": \"process\", \"target_label\": \"Pass\", \"type_of_edge\": \"solid\", \"relationship_value\": \"False\", \"relationship_type\": \"branches\"}, {\"source\": \"3\", \"source_type\": \"decision\", \"source_label\": \"Nested if condition\", \"target\": \"5\", \"target_type\": \"process\", \"target_label\": \"Nested if Body\", \"type_of_edge\": \"solid\", \"relationship_value\": \"True\", \"relationship_type\": \"branches\"}, {\"source\": \"4\", \"source_type\": \"process\", \"source_label\": \"If Body\", \"target\": \"7\", \"target_type\": \"process\", \"target_label\": \"Statement just below if\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"5\", \"source_type\": \"process\", \"source_label\": \"Nested if Body\", \"target\": \"7\", \"target_type\": \"process\", \"target_label\": \"Statement just below if\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"6\", \"source_type\": \"process\", \"source_label\": \"Pass\", \"target\": \"7\", \"target_type\": \"process\", \"target_label\": \"Statement just below if\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"7\", \"source_type\": \"process\", \"source_label\": \"Statement just below if\", \"target\": \"8\", \"target_type\": \"terminator\", \"target_label\": \"Exit\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}]}\n",
      "Score: 1.0\n",
      "Checkpoint saved at qwen2.5-3b-instruct-diagram-json/7\n",
      "Checkpoint saved at qwen2.5-3b-instruct-diagram-json/8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5a18b2584ed41928e6529b16810fd24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON : assistant\n",
      "{\"nodes\": [{\"id\": \"1\", \"type_of_node\": \"start\", \"shape\": \"start_event\", \"label\": \"Start\"}, {\"id\": \"2\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Order 1\"}, {\"id\": \"3\", \"type_of_node\": \"decision\", \"shape\": \"gateway\", \"label\": \"Accept?\"}, {\"id\": \"4\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Create\"}, {\"id\": \"5\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Flowchart\"}, {\"id\": \"6\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Document\"}, {\"id\": \"7\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Code\"}, {\"id\": \"8\", \"type_of_node\": \"terminator\", \"shape\": \"end_event\", \"label\": \"End\"}], \"edges\": [{\"source\": \"1\", \"source_type\": \"start\", \"source_label\": \"Start\", \"target\": \"2\", \"target_type\": \"process\", \"target_label\": \"Order 1\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"2\", \"source_type\": \"process\", \"source_label\": \"Order 1\", \"target\": \"3\", \"target_type\": \"decision\", \"target_label\": \"Accept?\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"3\", \"source_type\": \"decision\", \"source_label\": \"Accept?\", \"target\": \"4\", \"target_type\": \"process\", \"target_label\": \"Create\", \"type_of_edge\": \"solid\", \"relationship_value\": \"Yes\", \"relationship_type\": \"branches\"}, {\"source\": \"3\", \"source_type\": \"decision\", \"source_label\": \"Accept?\", \"target\": \"5\", \"target_type\": \"process\", \"target_label\": \"Flowchart\", \"type_of_edge\": \"solid\", \"relationship_value\": \"No\", \"relationship_type\": \"branches\"}, {\"source\": \"4\", \"source_type\": \"process\", \"source_label\": \"Create\", \"target\": \"6\", \"target_type\": \"process\", \"target_label\": \"Document\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"5\", \"source_type\": \"process\", \"source_label\": \"Flowchart\", \"target\": \"6\", \"target_type\": \"process\", \"target_label\": \"Document\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"6\", \"source_type\": \"process\", \"source_label\": \"Document\", \"target\": \"7\", \"target_type\": \"process\", \"target_label\": \"Code\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"7\", \"source_type\": \"process\", \"source_label\": \"Code\", \"target\": \"8\", \"target_type\": \"terminator\", \"target_label\": \"End\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}]}\n",
      "Ground Truth(JSON): {\"nodes\": [{\"id\": \"1\", \"type_of_node\": \"start\", \"shape\": \"start_event\", \"label\": \"Start\"}, {\"id\": \"2\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Order 1\"}, {\"id\": \"3\", \"type_of_node\": \"decision\", \"shape\": \"gateway\", \"label\": \"Accept?\"}, {\"id\": \"4\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Create\"}, {\"id\": \"5\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Flowchart\"}, {\"id\": \"6\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Document\"}, {\"id\": \"7\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Code\"}, {\"id\": \"8\", \"type_of_node\": \"terminator\", \"shape\": \"end_event\", \"label\": \"End\"}], \"edges\": [{\"source\": \"1\", \"source_type\": \"start\", \"source_label\": \"Start\", \"target\": \"2\", \"target_type\": \"process\", \"target_label\": \"Order 1\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"2\", \"source_type\": \"process\", \"source_label\": \"Order 1\", \"target\": \"3\", \"target_type\": \"decision\", \"target_label\": \"Accept?\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"3\", \"source_type\": \"decision\", \"source_label\": \"Accept?\", \"target\": \"4\", \"target_type\": \"process\", \"target_label\": \"Create\", \"type_of_edge\": \"solid\", \"relationship_value\": \"Yes\", \"relationship_type\": \"branches\"}, {\"source\": \"4\", \"source_type\": \"process\", \"source_label\": \"Create\", \"target\": \"5\", \"target_type\": \"process\", \"target_label\": \"Flowchart\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"3\", \"source_type\": \"decision\", \"source_label\": \"Accept?\", \"target\": \"6\", \"target_type\": \"process\", \"target_label\": \"Document\", \"type_of_edge\": \"solid\", \"relationship_value\": \"No\", \"relationship_type\": \"branches\"}, {\"source\": \"5\", \"source_type\": \"process\", \"source_label\": \"Flowchart\", \"target\": \"6\", \"target_type\": \"process\", \"target_label\": \"Document\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"6\", \"source_type\": \"process\", \"source_label\": \"Document\", \"target\": \"7\", \"target_type\": \"process\", \"target_label\": \"Code\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"7\", \"source_type\": \"process\", \"source_label\": \"Code\", \"target\": \"8\", \"target_type\": \"terminator\", \"target_label\": \"End\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}]}\n",
      "Score: 0.022222222222222223\n",
      "Generated JSON : \n",
      "Ground Truth(JSON): {\"nodes\": [{\"id\": \"1\", \"type_of_node\": \"start\", \"shape\": \"start_event\", \"label\": \"Start\"}, {\"id\": \"2\", \"type_of_node\": \"decision\", \"shape\": \"gateway\", \"label\": \"If condition\"}, {\"id\": \"3\", \"type_of_node\": \"decision\", \"shape\": \"gateway\", \"label\": \"Nested if condition\"}, {\"id\": \"4\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"If Body\"}, {\"id\": \"5\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Nested if Body\"}, {\"id\": \"6\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Pass\"}, {\"id\": \"7\", \"type_of_node\": \"process\", \"shape\": \"task\", \"label\": \"Statement just below if\"}, {\"id\": \"8\", \"type_of_node\": \"terminator\", \"shape\": \"end_event\", \"label\": \"Exit\"}], \"edges\": [{\"source\": \"1\", \"source_type\": \"start\", \"source_label\": \"Start\", \"target\": \"2\", \"target_type\": \"decision\", \"target_label\": \"If condition\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"2\", \"source_type\": \"decision\", \"source_label\": \"If condition\", \"target\": \"3\", \"target_type\": \"decision\", \"target_label\": \"Nested if condition\", \"type_of_edge\": \"solid\", \"relationship_value\": \"False\", \"relationship_type\": \"branches\"}, {\"source\": \"2\", \"source_type\": \"decision\", \"source_label\": \"If condition\", \"target\": \"4\", \"target_type\": \"process\", \"target_label\": \"If Body\", \"type_of_edge\": \"solid\", \"relationship_value\": \"True\", \"relationship_type\": \"branches\"}, {\"source\": \"3\", \"source_type\": \"decision\", \"source_label\": \"Nested if condition\", \"target\": \"6\", \"target_type\": \"process\", \"target_label\": \"Pass\", \"type_of_edge\": \"solid\", \"relationship_value\": \"False\", \"relationship_type\": \"branches\"}, {\"source\": \"3\", \"source_type\": \"decision\", \"source_label\": \"Nested if condition\", \"target\": \"5\", \"target_type\": \"process\", \"target_label\": \"Nested if Body\", \"type_of_edge\": \"solid\", \"relationship_value\": \"True\", \"relationship_type\": \"branches\"}, {\"source\": \"4\", \"source_type\": \"process\", \"source_label\": \"If Body\", \"target\": \"7\", \"target_type\": \"process\", \"target_label\": \"Statement just below if\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"5\", \"source_type\": \"process\", \"source_label\": \"Nested if Body\", \"target\": \"7\", \"target_type\": \"process\", \"target_label\": \"Statement just below if\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"6\", \"source_type\": \"process\", \"source_label\": \"Pass\", \"target\": \"7\", \"target_type\": \"process\", \"target_label\": \"Statement just below if\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}, {\"source\": \"7\", \"source_type\": \"process\", \"source_label\": \"Statement just below if\", \"target\": \"8\", \"target_type\": \"terminator\", \"target_label\": \"Exit\", \"type_of_edge\": \"solid\", \"relationship_value\": \"\", \"relationship_type\": \"follows\"}]}\n",
      "Score: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : wise_pear_5739\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/mohammedsafvan/qwen2-5-vl-finetune/1bf2a0473f5c4c4cb18e2a22a4eda764\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [100]            : (0.00012576776498463005, 0.3202984631061554)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_loss [130]      : (0.001706618582829833, 2.562387704849243)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_edit_distance [5] : (0.5111111402511597, 0.9231404662132263)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-environment-definition : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-info                   : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-specification          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git-patch (uncompressed)     : 1 (1.71 KB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages           : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph                  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages                  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code                  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at qwen2.5-3b-instruct-diagram-json/9\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exist_ok' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_module\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:538\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     50\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:574\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    568\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    570\u001b[0m     ckpt_path,\n\u001b[1;32m    571\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    572\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    573\u001b[0m )\n\u001b[0;32m--> 574\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:981\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    978\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    986\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1025\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[1;32m   1024\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1025\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:211\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_run_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:405\u001b[0m, in \u001b[0;36m_FitLoop.on_run_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    402\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: train run ended\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    404\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\n\u001b[0;32m--> 405\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_callback_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_train_end\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    406\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(trainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_train_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    407\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_strategy_hook(trainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_train_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:218\u001b[0m, in \u001b[0;36m_call_callback_hooks\u001b[0;34m(trainer, hook_name, monitoring_callbacks, *args, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(fn):\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Callback]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcallback\u001b[38;5;241m.\u001b[39mstate_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 218\u001b[0m             \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pl_module:\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "Cell \u001b[0;32mIn[24], line 24\u001b[0m, in \u001b[0;36mSaveCheckpoint.on_train_end\u001b[0;34m(self, trainer, pl_module)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer, pl_module):\n\u001b[1;32m     23\u001b[0m   checkpoint_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/latest\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 24\u001b[0m   os\u001b[38;5;241m.\u001b[39mmakedirs(checkpoint_path, \u001b[43mexist_ok\u001b[49m\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     26\u001b[0m   pl_module\u001b[38;5;241m.\u001b[39mprocessor\u001b[38;5;241m.\u001b[39msave_pretrained(checkpoint_path)\n\u001b[1;32m     27\u001b[0m   pl_module\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39msave_pretrained(checkpoint_path)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exist_ok' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.fit(model_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The last epoch(9) is same as the latest checkpoint; so no need to load the checkpoint for more training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
